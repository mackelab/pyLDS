{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import division\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pybasicbayes.distributions import Regression\n",
    "from pybasicbayes.util.text import progprint_xrange\n",
    "from autoregressive.distributions import AutoRegression\n",
    "\n",
    "from scipy.io import loadmat\n",
    "import glob, os\n",
    "from scipy.io import savemat # store results for comparison with Matlab code   \n",
    "from scipy.linalg import solve_discrete_lyapunov as dtlyap # solve discrete-time Lyapunov equation\n",
    "\n",
    "absolute_code_path = '/home/marcel/Desktop/Projects/Stitching/code/pyLDS_dev/'\n",
    "os.chdir(absolute_code_path +'pylds')\n",
    "\n",
    "from pylds.models import LDS, DefaultLDS\n",
    "from pylds.distributions import Regression_diag, AutoRegression_input\n",
    "from pylds.obs_scheme import ObservationScheme\n",
    "from pylds.user_util import gen_pars, rand_rotation_matrix, init_LDS_model, collect_LDS_stats\n",
    "\n",
    "def update(model):\n",
    "    model.EM_step()\n",
    "    return model.log_likelihood() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit models for illustration #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "filenames = glob.glob(\"*.npz\")\n",
    "num_exps = len(filenames)\n",
    "idx_exps = range(num_exps)\n",
    "\n",
    "def update(model):\n",
    "    model.EM_step()\n",
    "    return model.log_likelihood()\n",
    "        \n",
    "eps = np.log(1.01)\n",
    "max_iter = 25\n",
    "\n",
    "#initialisers = ['params', 'params_flip', 'params_naive', 'params_naive_flip', 'random']\n",
    "initialisers = ['params', 'params_flip', 'random']\n",
    "\n",
    "for i in idx_exps:\n",
    "    \n",
    "    ##################\n",
    "    # load the data  #\n",
    "    ##################\n",
    "    \n",
    "    filename = filenames[i]\n",
    "\n",
    "    os.chdir('../data/')    \n",
    "    loadfile = np.load(filename)\n",
    "\n",
    "    data = loadfile['y']\n",
    "    T,p = data.shape\n",
    "    n   = loadfile['x'].shape[1]\n",
    "    obs_scheme = ObservationScheme(p=p, T=T, \n",
    "                                   sub_pops=tuple([item for item in loadfile['sub_pops']]),\n",
    "                                   obs_pops=loadfile['obs_pops'], \n",
    "                                   obs_time=loadfile['obs_time'])\n",
    "    pars_true = loadfile['truePars'].reshape(1,)[0] # some numpy (cross-version 3.x-2.x?)     \n",
    "    tmp = {}\n",
    "    for j in range(len(pars_true.keys())):\n",
    "        tmp[str(pars_true.keys()[j])] =  pars_true.values()[j]\n",
    "    pars_true = tmp    \n",
    "\n",
    "    print('dataset #', i)\n",
    "    print('(T, p, n, eps) = ', (T, p, n, eps))\n",
    "    \n",
    "    ####################\n",
    "    # pick initialiser #\n",
    "    ####################\n",
    "\n",
    "    \n",
    "    for initialiser in initialisers:\n",
    "        \n",
    "        print('initialiser ', initialiser)\n",
    "\n",
    "        if initialiser in ['params', 'params_flip', 'params_naive', 'params_naive_flip']:\n",
    "            os.chdir('../init/')\n",
    "\n",
    "            num_reps = 1\n",
    "            \n",
    "            loadfile = np.load('init_'+filename)\n",
    "\n",
    "            initkey =  initialiser[:-5] if initialiser[-5:]=='_flip' else initialiser\n",
    "            \n",
    "            pars_init = loadfile[initkey].reshape(1,)[0]\n",
    "            tmp = {}\n",
    "            for j in range(len(pars_init.keys())):\n",
    "                tmp[str(pars_init.keys()[j])] =  pars_init.values()[j]\n",
    "            pars_init = tmp    \n",
    "\n",
    "            pars_init['R'] = np.diag(pars_init['R'])\n",
    "            \n",
    "            # for SSID-derived initialisers, also try out flipping parts of C\n",
    "            if initialiser[-5:]=='_flip':\n",
    "                idx0_no_overlap = np.setdiff1d(np.arange(p),obs_scheme.sub_pops[1]) \n",
    "                pars_init['C'][idx0_no_overlap,:] *= -1\n",
    "\n",
    "\n",
    "        elif initialiser=='random':\n",
    "            \n",
    "            num_reps = 10\n",
    "            \n",
    "        else:\n",
    "            raise Exception('unexpected initialiser!')\n",
    "\n",
    "        \n",
    "        for rep in range(num_reps):\n",
    "\n",
    "            print( 'run #' + str(rep+1) +'/' +str(num_reps) )\n",
    "            \n",
    "            if initialiser=='random':\n",
    "\n",
    "                pars_init, _ = gen_pars(n, p, u_dim=0, \n",
    "                                     pars_in=None, \n",
    "                                     obs_scheme=obs_scheme,\n",
    "                                     gen_A='diagonal', lts=0.99 * np.ones((n,)),\n",
    "                                     gen_B='random', \n",
    "                                     gen_Q='identity', \n",
    "                                     gen_mu0='random', \n",
    "                                     gen_V0='identity', \n",
    "                                     gen_C='random', \n",
    "                                     gen_d='mean', \n",
    "                                     gen_R='fractionObserved',\n",
    "                                     diag_R_flag=True,\n",
    "                                     x=None, y=data.T, u=None)    \n",
    "\n",
    "            ###################\n",
    "            #    EM cycles    #\n",
    "            ###################\n",
    "\n",
    "            try:\n",
    "                # get EM-step results after m iterations                    \n",
    "                model = init_LDS_model(pars_init, data, obs_scheme) # reset to initialisation                    \n",
    "                print 'fitting #' + str(i)    \n",
    "                likes = [-np.inf]\n",
    "                for t in progprint_xrange(max_iter):\n",
    "                    likes.append(update(model))\n",
    "                    if likes[-1]-likes[-2] < eps:\n",
    "                        break\n",
    "\n",
    "                stats_hat,pars_hat = collect_LDS_stats(model)\n",
    "\n",
    "                # get EM-step results from true parameters\n",
    "                model = init_LDS_model(pars_true, data, obs_scheme) # reset to true pars\n",
    "                model.E_step()\n",
    "                stats_true,_ = collect_LDS_stats(model)\n",
    "                model.M_step()\n",
    "                \n",
    "                broken = False\n",
    "                y_out = model.states_list[0].data\n",
    "                x_out = model.states_list[0].stateseq\n",
    "                Pi = dtlyap(pars_true['A'], pars_true['Q'])\n",
    "                Pi_h = dtlyap(pars_hat['A'], pars_hat['Q'])\n",
    "                Pi_t = pars_true['A'].dot(dtlyap(pars_true['A'], pars_true['Q']))\n",
    "                Pi_t_h = pars_hat['A'].dot(dtlyap(pars_hat['A'], pars_hat['Q']))\n",
    "                \n",
    "                \n",
    "            except:\n",
    "                print('')\n",
    "                print('############')\n",
    "                print('#RUN BROKE!#')\n",
    "                print('############')\n",
    "                print('')\n",
    "                \n",
    "                broken = True\n",
    "                y_out = model.states_list[0].data\n",
    "                x_out = []\n",
    "                pars_hat, stats_h, stats_true = [],[],[]\n",
    "                Pi, Pi_h, Pi_t, Pi_t_h = 0,0,0,0\n",
    "                \n",
    "            ###################\n",
    "            #  store results  #\n",
    "            ###################\n",
    "\n",
    "            print('finished in ' + str(len(likes)-1) + ' many steps.')\n",
    "\n",
    "            os.chdir('../fits/')\n",
    "\n",
    "            save_file = initialiser + '_idx' + str(rep) + '_' + filename\n",
    "\n",
    "            save_file_m = {'ifBroken':broken,\n",
    "                           'x': x_out, \n",
    "                           'y': y_out,\n",
    "                           'u' : [], \n",
    "                           'll' : likes, \n",
    "                           'T' : model.states_list[0].T, \n",
    "                           'Trial': len(model.states_list), \n",
    "                           'ifUseB':False, \n",
    "                           'ifUseA':True, \n",
    "                           'epsilon':eps,\n",
    "                           'truePars':pars_true,\n",
    "                           'initPars':pars_init,\n",
    "                           'estPars': pars_hat,\n",
    "                           'stats_h': stats_hat,\n",
    "                           'stats_true': stats_true,\n",
    "                           'Pi':Pi,\n",
    "                           'Pi_h':Pi_h,\n",
    "                           'Pi_t':Pi_t,\n",
    "                           'Pi_t_h':Pi_t_h,\n",
    "                           'obsScheme' : obs_scheme}\n",
    "            savemat(save_file,save_file_m) # does the actual saving\n",
    "\n",
    "            np.savez(save_file, \n",
    "                    broken=broken,\n",
    "                    x=x_out,\n",
    "                    y=y_out,\n",
    "                    ll=likes,\n",
    "                    T=model.states_list[0].T, \n",
    "                    Trial=len(model.states_list), \n",
    "                    ifUseA=True,\n",
    "                    ifUseB=False,\n",
    "                    epsilon=eps,\n",
    "                    initPars=pars_init,\n",
    "                    truePars=pars_true,\n",
    "                    estPars =pars_hat,\n",
    "                    stats_h = stats_hat,\n",
    "                    stats_true = stats_true,\n",
    "                    Pi=Pi,\n",
    "                    Pi_h=Pi_h,\n",
    "                    Pi_t=Pi_t,\n",
    "                    Pi_t_h=Pi_t_h,\n",
    "                    sub_pops=obs_scheme.sub_pops,            \n",
    "                    obs_time=obs_scheme.obs_time,            \n",
    "                    obs_pops=obs_scheme.obs_pops)     \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit models for simulation #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "relative_data_path = '../../../results/cosyne_poster/simulation_1/data'\n",
    "os.chdir(relative_data_path)\n",
    "filenames = glob.glob(\"*.npz\")\n",
    "num_exps = len(filenames)\n",
    "idx_exps = range(num_exps)\n",
    "\n",
    "def update(model):\n",
    "    model.EM_step()\n",
    "    return model.log_likelihood()\n",
    "        \n",
    "eps = np.log(1.01)\n",
    "max_iter = 25\n",
    "\n",
    "initialisers = ['params', 'params_flip', 'params_naive', 'params_naive_flip', 'random']\n",
    "\n",
    "for i in idx_exps:\n",
    "    \n",
    "    ##################\n",
    "    # load the data  #\n",
    "    ##################\n",
    "    \n",
    "    filename = filenames[i]\n",
    "\n",
    "    os.chdir('../data/')    \n",
    "    loadfile = np.load(filename)\n",
    "\n",
    "    data = loadfile['y']\n",
    "    T,p = data.shape\n",
    "    n   = loadfile['x'].shape[1]\n",
    "    sub_pops = tuple([item for item in loadfile['sub_pops']])\n",
    "    obs_pops = loadfile['obs_pops']\n",
    "\n",
    "    pars_true = loadfile['truePars'].reshape(1,)[0] # some numpy (cross-version 3.x-2.x?)     \n",
    "    tmp = {}\n",
    "    for j in range(len(pars_true.keys())):\n",
    "        tmp[str(pars_true.keys()[j])] =  pars_true.values()[j]\n",
    "    pars_true = tmp    \n",
    "\n",
    "    print('dataset #', i)\n",
    "    print('(T, p, n, eps) = ', (T, p, n, eps))\n",
    "    \n",
    "    ####################\n",
    "    # pick initialiser #\n",
    "    ####################\n",
    "\n",
    "    \n",
    "    for initialiser in initialisers:\n",
    "        \n",
    "        print('initialiser ', initialiser)\n",
    "\n",
    "        if initialiser in ['params', 'params_flip', 'params_naive', 'params_naive_flip']:\n",
    "            os.chdir('../init/')\n",
    "\n",
    "            num_reps = 1\n",
    "            \n",
    "            loadfile = np.load('init_'+filename)\n",
    "\n",
    "            initkey =  initialiser[:-5] if initialiser[-5:]=='_flip' else initialiser\n",
    "            \n",
    "            pars_init = loadfile[initkey].reshape(1,)[0]\n",
    "            tmp = {}\n",
    "            for j in range(len(pars_init.keys())):\n",
    "                tmp[str(pars_init.keys()[j])] =  pars_init.values()[j]\n",
    "            pars_init = tmp    \n",
    "\n",
    "            pars_init['R'] = np.diag(pars_init['R'])\n",
    "            \n",
    "            # for SSID-derived initialisers, also try out flipping parts of C\n",
    "            if initialiser[-5:]=='_flip':\n",
    "                idx0_no_overlap = np.setdiff1d(np.arange(p),obs_scheme.sub_pops[1]) \n",
    "                pars_init['C'][idx0_no_overlap,:] *= -1\n",
    "\n",
    "\n",
    "        elif initialiser=='random':\n",
    "            \n",
    "            num_reps = 10\n",
    "            \n",
    "        else:\n",
    "            raise Exception('unexpected initialiser!')\n",
    "\n",
    "        \n",
    "        for rep in range(num_reps):\n",
    "\n",
    "            print( 'run #' + str(rep+1) +'/' +str(num_reps) )\n",
    "            \n",
    "            if initialiser=='random':\n",
    "\n",
    "                pars_init, _ = gen_pars(n, p, u_dim=0, \n",
    "                                     pars_in=None, \n",
    "                                     obs_scheme=obs_scheme,\n",
    "                                     gen_A='diagonal', lts=0.99 * np.ones((n,)),\n",
    "                                     gen_B='random', \n",
    "                                     gen_Q='identity', \n",
    "                                     gen_mu0='random', \n",
    "                                     gen_V0='identity', \n",
    "                                     gen_C='random', \n",
    "                                     gen_d='mean', \n",
    "                                     gen_R='fractionObserved',\n",
    "                                     diag_R_flag=True,\n",
    "                                     x=None, y=data.T, u=None)    \n",
    "\n",
    "            ###################\n",
    "            #    EM cycles    #\n",
    "            ###################\n",
    "\n",
    "            try:\n",
    "                \n",
    "                # get EM-step results from true parameters\n",
    "                model = init_LDS_model(pars_true, data, obs_scheme) # reset to true pars\n",
    "                model.E_step()\n",
    "                stats_true,_ = collect_LDS_stats(model)\n",
    "                \n",
    "                # get EM-step results after m iterations                    \n",
    "                model = init_LDS_model(pars_init, data, obs_scheme) # reset to initialisation                    \n",
    "                print 'fitting #' + str(i)    \n",
    "                likes = [-np.inf]\n",
    "                for t in progprint_xrange(max_iter):\n",
    "                    likes.append(update(model))\n",
    "                    if likes[-1]-likes[-2] < eps:\n",
    "                        break\n",
    "\n",
    "                stats_hat,pars_hat = collect_LDS_stats(model)\n",
    "                \n",
    "                broken = False\n",
    "                y_out = model.states_list[0].data\n",
    "                x_out = model.states_list[0].stateseq\n",
    "                Pi = dtlyap(pars_true['A'], pars_true['Q'])\n",
    "                Pi_h = dtlyap(pars_hat['A'], pars_hat['Q'])\n",
    "                Pi_t = pars_true['A'].dot(dtlyap(pars_true['A'], pars_true['Q']))\n",
    "                Pi_t_h = pars_hat['A'].dot(dtlyap(pars_hat['A'], pars_hat['Q']))\n",
    "                \n",
    "                \n",
    "            except:\n",
    "                print('')\n",
    "                print('############')\n",
    "                print('#RUN BROKE!#')\n",
    "                print('############')\n",
    "                print('')\n",
    "                \n",
    "                broken = True\n",
    "                y_out = []\n",
    "                x_out = []\n",
    "                pars_hat, stats_hat, stats_true = [],[],[]\n",
    "                Pi, Pi_h, Pi_t, Pi_t_h = 0,0,0,0\n",
    "                \n",
    "            ###################\n",
    "            #  store results  #\n",
    "            ###################\n",
    "\n",
    "            print('finished in ' + str(len(likes)-1) + ' many steps.')\n",
    "\n",
    "            os.chdir('../fits/')\n",
    "\n",
    "            save_file = initialiser + '_idx' + str(rep) + '_' + filename\n",
    "\n",
    "            save_file_m = {'ifBroken':broken,\n",
    "                           'x': x_out, \n",
    "                           'y': y_out,\n",
    "                           'u' : [], \n",
    "                           'll' : likes, \n",
    "                           'T' : model.states_list[0].T, \n",
    "                           'Trial': len(model.states_list), \n",
    "                           'ifUseB':False, \n",
    "                           'ifUseA':True, \n",
    "                           'epsilon':eps,\n",
    "                           'truePars':pars_true,\n",
    "                           'initPars':pars_init,\n",
    "                           'estPars': pars_hat,\n",
    "                           'stats_h': stats_hat,\n",
    "                           'stats_true': stats_true,\n",
    "                           'Pi':Pi,\n",
    "                           'Pi_h':Pi_h,\n",
    "                           'Pi_t':Pi_t,\n",
    "                           'Pi_t_h':Pi_t_h,\n",
    "                           'obsScheme' : obs_scheme}\n",
    "            savemat(save_file,save_file_m) # does the actual saving\n",
    "\n",
    "            np.savez(save_file, \n",
    "                    broken=broken,\n",
    "                    ll=likes,\n",
    "                    T=model.states_list[0].T, \n",
    "                    Trial=len(model.states_list), \n",
    "                    ifUseA=True,\n",
    "                    ifUseB=False,\n",
    "                    epsilon=eps,\n",
    "                    initPars=pars_init,\n",
    "                    truePars=pars_true,\n",
    "                    estPars =pars_hat,\n",
    "                    stats_h = stats_hat,\n",
    "                    stats_true = stats_true,\n",
    "                    Pi=Pi,\n",
    "                    Pi_h=Pi_h,\n",
    "                    Pi_t=Pi_t,\n",
    "                    Pi_t_h=Pi_t_h,\n",
    "                    sub_pops=obs_scheme.sub_pops,            \n",
    "                    obs_time=obs_scheme.obs_time,            \n",
    "                    obs_pops=obs_scheme.obs_pops)     \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Fit models for simulation #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "relative_data_path = '../../../results/cosyne_poster/simulation_2/data'\n",
    "os.chdir(relative_data_path)\n",
    "filenames = glob.glob(\"*.npz\")\n",
    "num_exps = len(filenames)\n",
    "idx_exps = range(num_exps)\n",
    "        \n",
    "eps = np.log(1.01)\n",
    "max_iter = 50\n",
    "\n",
    "initialisers = ['params', 'params_flip', 'params_naive', 'params_naive_flip', 'random']\n",
    "\n",
    "for idx in [0,2,5,9]:\n",
    "    \n",
    "    ##################\n",
    "    # load the data  #\n",
    "    ##################\n",
    "    \n",
    "    print('idx', idx)\n",
    "    filename = 'LDS_save_idx' + str(idx) + '.npz'\n",
    "    print(filename)\n",
    "\n",
    "    os.chdir('../data/')    \n",
    "    loadfile = np.load(filename)\n",
    "\n",
    "    data = loadfile['y']\n",
    "    T,p = data.shape\n",
    "    n   = loadfile['x'].shape[1]\n",
    "    \n",
    "    pars_true = loadfile['truePars'].reshape(1,)[0] # some numpy (cross-version 3.x-2.x?)     \n",
    "    tmp = {}\n",
    "    for j in range(len(pars_true.keys())):\n",
    "        tmp[str(pars_true.keys()[j])] =  pars_true.values()[j]\n",
    "    pars_true = tmp    \n",
    "\n",
    "    print('dataset #', idx)\n",
    "    print('(T, p, n, eps) = ', (T, p, n, eps))\n",
    "    \n",
    "    ####################\n",
    "    # pick initialiser #\n",
    "    ####################\n",
    "\n",
    "    os.chdir('../init/')\n",
    "    initfiles = glob.glob(\"*_LDS_save_idx\" + str(idx) + \".npz\")\n",
    "    num_prots = len(initfiles)\n",
    "    \n",
    "    for prot in [0,12]: #range(num_prots):\n",
    "        \n",
    "        initfile = initfiles[prot]\n",
    "        print('prot ' + str(prot) + '/' + str(num_prots))\n",
    "        os.chdir('../init/')\n",
    "        loadinit = np.load(initfile)\n",
    "\n",
    "        obs_scheme = ObservationScheme(p=p, T=T, \n",
    "                                   sub_pops=tuple([item for item in loadinit['sub_pops']]),\n",
    "                                   obs_pops=loadinit['obs_pops'], \n",
    "                                   obs_time=loadinit['obs_time'])\n",
    "        \n",
    "        for initialiser in initialisers:\n",
    "\n",
    "            print('initialiser ', initialiser)\n",
    "            if initialiser in ['params', 'params_flip', 'params_naive', 'params_naive_flip']:\n",
    "                \n",
    "                num_repets = 1\n",
    "                initkey =  initialiser[:-5] if initialiser[-5:]=='_flip' else initialiser\n",
    "\n",
    "                pars_init = loadinit[initkey].reshape(1,)[0]\n",
    "                tmp = {}\n",
    "                for j in range(len(pars_init.keys())):\n",
    "                    tmp[str(pars_init.keys()[j])] =  pars_init.values()[j]\n",
    "                pars_init = tmp    \n",
    "\n",
    "                pars_init['R'] = np.diag(pars_init['R'])\n",
    "\n",
    "                # for SSID-derived initialisers, also try out flipping parts of C\n",
    "                if initialiser[-5:]=='_flip':\n",
    "                    idx0_no_overlap = np.setdiff1d(np.arange(p),obs_scheme.sub_pops[1]) \n",
    "                    pars_init['C'][idx0_no_overlap,:] *= -1\n",
    "\n",
    "\n",
    "            elif initialiser=='random':\n",
    "\n",
    "                num_repets = 5\n",
    "\n",
    "            else:\n",
    "                raise Exception('unexpected initialiser!')\n",
    "\n",
    "\n",
    "            for repet in range(num_repets):\n",
    "\n",
    "                print( 'run #' + str(repet+1) +'/' +str(num_repets) )\n",
    "\n",
    "                if initialiser=='random':\n",
    "\n",
    "                    pars_init, _ = gen_pars(n, p, u_dim=0, \n",
    "                                         pars_in=None, \n",
    "                                         obs_scheme=obs_scheme,\n",
    "                                         gen_A='diagonal', lts=0.99 * np.ones((n,)),\n",
    "                                         gen_B='random', \n",
    "                                         gen_Q='identity', \n",
    "                                         gen_mu0='random', \n",
    "                                         gen_V0='identity', \n",
    "                                         gen_C='random', \n",
    "                                         gen_d='mean', \n",
    "                                         gen_R='fractionObserved',\n",
    "                                         diag_R_flag=True,\n",
    "                                         x=None, y=data.T, u=None)    \n",
    "\n",
    "                ###################\n",
    "                #    EM cycles    #\n",
    "                ###################\n",
    "                likes = [-np.inf]\n",
    "                try:\n",
    "                    # get EM-step results after m iterations                    \n",
    "                    model = init_LDS_model(pars_init, data, obs_scheme) # reset to initialisation                    \n",
    "                    print 'fitting #' + str(idx)    \n",
    "                    for t in progprint_xrange(max_iter):\n",
    "                        likes.append(update(model))\n",
    "                        if likes[-1]-likes[-2] < eps:\n",
    "                            break\n",
    "\n",
    "                    stats_hat,pars_hat = collect_LDS_stats(model)\n",
    "\n",
    "                    # get EM-step results from true parameters\n",
    "                    model = init_LDS_model(pars_true, data, obs_scheme) # reset to true pars\n",
    "                    model.E_step()\n",
    "                    stats_true,_ = collect_LDS_stats(model)\n",
    "                    model.M_step()\n",
    "\n",
    "                    broken = False\n",
    "                    Pi = dtlyap(pars_true['A'], pars_true['Q'])\n",
    "                    Pi_h = dtlyap(pars_hat['A'], pars_hat['Q'])\n",
    "                    Pi_t = pars_true['A'].dot(dtlyap(pars_true['A'], pars_true['Q']))\n",
    "                    Pi_t_h = pars_hat['A'].dot(dtlyap(pars_hat['A'], pars_hat['Q']))\n",
    "\n",
    "\n",
    "                except:\n",
    "                    print('')\n",
    "                    print('############')\n",
    "                    print('#RUN BROKE!#')\n",
    "                    print('############')\n",
    "                    print('')\n",
    "\n",
    "                    broken = True\n",
    "                    pars_hat, stats_hat, stats_true = [],[],[]\n",
    "                    Pi, Pi_h, Pi_t, Pi_t_h = 0,0,0,0\n",
    "                    \n",
    "                if not broken:\n",
    "                    plt.figure(figsize=(25,25))\n",
    "                    plt.subplot(1,3,1)\n",
    "                    plt.imshow(np.cov(data.T),interpolation='none')\n",
    "                    plt.subplot(1,3,2)\n",
    "                    if initialiser=='random':\n",
    "                        pars_init['Pi'] = dtlyap(pars_init['A'], pars_init['Q'])\n",
    "                        R = pars_init['R']\n",
    "                    else:\n",
    "                        R = np.diag(pars_init['R'])\n",
    "                    plt.imshow(pars_init['C'].dot(pars_init['Pi']).dot(pars_init['C'].T) + R,interpolation='none')\n",
    "                    plt.subplot(1,3,3)\n",
    "                    plt.imshow(pars_hat['C'].dot(Pi_h).dot(pars_hat['C'].T) + pars_hat['R'],interpolation='none')   \n",
    "                    plt.show()\n",
    "\n",
    "                ###################\n",
    "                #  store results  #\n",
    "                ###################\n",
    "\n",
    "                print('finished in ' + str(len(likes)-1) + ' many steps.')\n",
    "\n",
    "                os.chdir('../fits/')\n",
    "\n",
    "                save_file = initialiser + '_prot' + str(prot) + '_rep' + str(repet) + '_' + filename\n",
    "\n",
    "                save_file_m = {'ifBroken':broken,\n",
    "                               'll' : likes, \n",
    "                               'T' : T, \n",
    "                               'Trial': 1, \n",
    "                               'ifUseB':False, \n",
    "                               'ifUseA':True, \n",
    "                               'epsilon':eps,\n",
    "                               'truePars':pars_true,\n",
    "                               'initPars':pars_init,\n",
    "                               'estPars': pars_hat,\n",
    "                               'stats_h': stats_hat,\n",
    "                               'stats_true': stats_true,\n",
    "                               'Pi':Pi,\n",
    "                               'Pi_h':Pi_h,\n",
    "                               'Pi_t':Pi_t,\n",
    "                               'Pi_t_h':Pi_t_h,\n",
    "                               'sub_pops':obs_scheme.sub_pops,            \n",
    "                               'obs_time':obs_scheme.obs_time,            \n",
    "                               'obs_pops':obs_scheme.obs_pops}\n",
    "                savemat(save_file,save_file_m) # does the actual saving\n",
    "\n",
    "                np.savez(save_file, \n",
    "                        broken=broken,\n",
    "                        ll=likes,\n",
    "                        T=T, \n",
    "                        Trial=1, \n",
    "                        ifUseA=True,\n",
    "                        ifUseB=False,\n",
    "                        epsilon=eps,\n",
    "                        initPars=pars_init,\n",
    "                        truePars=pars_true,\n",
    "                        estPars =pars_hat,\n",
    "                        stats_h = stats_hat,\n",
    "                        stats_true = stats_true,\n",
    "                        Pi=Pi,\n",
    "                        Pi_h=Pi_h,\n",
    "                        Pi_t=Pi_t,\n",
    "                        Pi_t_h=Pi_t_h,\n",
    "                        sub_pops=obs_scheme.sub_pops,            \n",
    "                        obs_time=obs_scheme.obs_time,            \n",
    "                        obs_pops=obs_scheme.obs_pops)     \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit big sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "           \n",
    "\n",
    "spikes = loadmat('/home/marcel/Desktop/Projects/Stitching/results/cosyne_poster/gb_net/spikes_20trials_10msBins')\n",
    "spikes= spikes['spikes_out']\n",
    "\n",
    "p, T = 1000, 6000\n",
    "idx_n = np.sort(np.random.choice(1000, size=p, replace=False))\n",
    "data = np.vstack([spikes[i][0].T[:,idx_n] for i in range(spikes.size)]).astype(np.float)\n",
    "T *= spikes.size\n",
    "\n",
    "n = 10\n",
    "\n",
    "#tmp = np.random.choice(np.arange(p),size=p,replace=False)\n",
    "#sub_pops = (np.sort(tmp[:p//2 + 2]), np.sort(tmp[p//2 - 2:]))\n",
    "sub_pops = (np.arange(p//2+100), np.arange(p//2-100, p))\n",
    "obs_pops = np.array((0,1))\n",
    "obs_time = np.array((T//2,T))\n",
    "obs_scheme = ObservationScheme(p, T, sub_pops, obs_pops, obs_time)\n",
    "\n",
    "###################\n",
    "#    EM cycles    #\n",
    "###################\n",
    "\n",
    "loadfile = np.load('/home/marcel/Desktop/Projects/Stitching/results/cosyne_poster/experiment_1/init/init_experiment.npz')\n",
    "neuron_shuffle = loadfile['neuron_shuffle']\n",
    "data = data[:,neuron_shuffle]\n",
    "\n",
    "initkey =  'params_naive'\n",
    "\n",
    "pars_init = loadfile[initkey].reshape(1,)[0]\n",
    "tmp = {}\n",
    "for j in range(len(pars_init.keys())):\n",
    "    tmp[str(pars_init.keys()[j])] =  pars_init.values()[j]\n",
    "pars_init = tmp    \n",
    "\n",
    "pars_init['R'] = np.diag(pars_init['R'])\n",
    "pars_init['V0'] = pars_init['Q']\n",
    "\n",
    "D, V = np.linalg.eig(pars_init['A'])\n",
    "if np.any(np.abs(D) > 1):\n",
    "    print(np.abs(D))\n",
    "    D /= np.maximum(np.abs(D), 1.0001)\n",
    "    print(np.abs(D))\n",
    "    pars_init['A'] = np.real(V.dot(np.diag(D).dot(np.linalg.inv(V))))\n",
    "\n",
    "model = init_LDS_model(pars_init, data, obs_scheme) # set to initialisation\n",
    "\n",
    "\n",
    "#stats_init,_ = collect_LDS_stats(model)\n",
    "\n",
    "print 'fitting'\n",
    "likes = [update(model) for _ in progprint_xrange(100)]\n",
    "stats_hat,pars_hat = collect_LDS_stats(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.io import savemat\n",
    "broken = False\n",
    "save_file = '/home/marcel/Desktop/Projects/Stitching/results/cosyne_poster/experiment_1/fits/params_naive_p1000_iter100'\n",
    "\n",
    "eps = - np.inf\n",
    "save_file_m = {'ifBroken':broken,\n",
    "               'll' : likes, \n",
    "               'T' : model.states_list[0].T, \n",
    "               'Trial': len(model.states_list), \n",
    "               'epsilon':eps,\n",
    "               'initPars':pars_init,\n",
    "               'estPars': pars_hat,\n",
    "               'stats_h': stats_hat,\n",
    "               'sub_pops' : obs_scheme.sub_pops,\n",
    "               'obs_pops' : obs_scheme.obs_pops,\n",
    "               'obs_time' : obs_scheme.obs_time}\n",
    "\n",
    "savemat(save_file,save_file_m) # does the actual saving\n",
    "\n",
    "np.savez(save_file, \n",
    "        broken=broken,\n",
    "        ll=likes,\n",
    "        T=model.states_list[0].T, \n",
    "        Trial=len(model.states_list), \n",
    "        epsilon=eps,\n",
    "        initPars=pars_init,\n",
    "        estPars =pars_hat,\n",
    "        stats_h = stats_hat,\n",
    "        sub_pops=obs_scheme.sub_pops,            \n",
    "        obs_time=obs_scheme.obs_time,            \n",
    "        obs_pops=obs_scheme.obs_pops)     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize goodnes of EM fit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "spikes = loadmat('/home/marcel/Desktop/Projects/Stitching/results/cosyne_poster/gb_net/spikes_20trials_10msBins')\n",
    "spikes= spikes['spikes_out']\n",
    "\n",
    "# get neuron_shuffle\n",
    "loadfile = np.load('/home/marcel/Desktop/Projects/Stitching/results/cosyne_poster/experiment_1/init/init_experiment.npz')\n",
    "neuron_shuffle = loadfile['neuron_shuffle']\n",
    "\n",
    "# get param EM fit\n",
    "loadfile = np.load('/home/marcel/Desktop/Projects/Stitching/results/cosyne_poster/experiment_1/fits/params_naive_p1000_iter400.npz')\n",
    "pars_hat = loadfile['estPars'].reshape(1,)[0]\n",
    "likes = loadfile['ll']\n",
    "\n",
    "p, T = spikes[0][0].shape\n",
    "idx_n = np.sort(np.random.choice(1000, size=p, replace=False))\n",
    "data = np.vstack([spikes[i][0].T[:,idx_n] for i in range(spikes.size)]).astype(np.float)\n",
    "T *= spikes.size\n",
    "\n",
    "n = 10\n",
    "\n",
    "data = data[:,neuron_shuffle]\n",
    "initkey =  'params_naive'\n",
    "\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "Pi = sp.linalg.solve_discrete_lyapunov(pars_hat['A'], pars_hat['Q'])\n",
    "\n",
    "plt.figure(1,figsize=(15,22))\n",
    "try:\n",
    "    Pi_true = sp.linalg.solve_discrete_lyapunov(pars_true['A'], pars_true['Q'])\n",
    "    tmp1 = pars_true['C'].dot(Pi_true.dot(pars_true['C'].transpose())) + np.diag(pars_true['R'])\n",
    "except:\n",
    "    cov_all = np.cov(np.hstack([data[1:], data[:-1]]).T)\n",
    "    tmp1 = cov_all[np.ix_(np.arange(p), np.arange(p))]\n",
    "tmp2 = pars_hat['C'].dot(Pi.dot(pars_hat['C'].transpose())) + pars_hat['R']    \n",
    "m = np.min((tmp1-np.diag(np.diag(tmp1))).min(),(tmp2-np.diag(np.diag(tmp2))).min())\n",
    "M = np.max((tmp1-np.diag(np.diag(tmp1))).max(),(tmp2-np.diag(np.diag(tmp2))).max())\n",
    "\n",
    "plt.subplot(2,3,1)\n",
    "plt.imshow(tmp1-np.diag(np.diag(tmp1)),interpolation='none')\n",
    "plt.clim(m,M)\n",
    "plt.colorbar()\n",
    "plt.title('true instantaneous covs')\n",
    "plt.subplot(2,3,2)\n",
    "plt.imshow(tmp2-np.diag(np.diag(tmp2)), interpolation='none')\n",
    "plt.clim(m,M)\n",
    "plt.colorbar()\n",
    "plt.title('estimated instantaneous covs')\n",
    "plt.subplot(2,3,3)\n",
    "plt.plot(tmp1[:], tmp2[:], '.')\n",
    "plt.xlabel('true')\n",
    "plt.ylabel('est')\n",
    "\n",
    "try:\n",
    "    tmp1 = pars_true['C'].dot(pars_true['A']).dot(Pi_true.dot(pars_true['C'].transpose()))\n",
    "except:\n",
    "    tmp1 = cov_all[np.ix_(np.arange(0, p), np.arange(p+1 , 2*p))]\n",
    "tmp2 = pars_hat['C'].dot(pars_hat['A']).dot(Pi.dot(pars_hat['C'].transpose()))     \n",
    "m = np.min(tmp1.min(),tmp2.min())\n",
    "M = np.max(tmp1.max(),tmp2.max())\n",
    "\n",
    "plt.subplot(2,3,4)\n",
    "plt.imshow(tmp1,interpolation='none')\n",
    "plt.clim(m,M)\n",
    "plt.colorbar()\n",
    "plt.title('true time_lagged covs')\n",
    "plt.subplot(2,3,5)\n",
    "plt.imshow(tmp2, interpolation='none')\n",
    "plt.clim(m,M)\n",
    "plt.colorbar()\n",
    "plt.title('estimated time-lagged covs')\n",
    "plt.subplot(2,3,6)\n",
    "plt.plot(tmp1[:], tmp2[:], '.')\n",
    "plt.xlabel('true')\n",
    "plt.ylabel('est')\n",
    "\n",
    "\n",
    "plt.figure(2,figsize=(15,15))\n",
    "plt.subplot(2,2,1)\n",
    "plt.plot(pars_hat['d'])\n",
    "try:\n",
    "    plt.plot(pars_true['d'])\n",
    "except:\n",
    "    pass\n",
    "plt.legend(['true', 'est'])\n",
    "plt.title('d')\n",
    "plt.subplot(2,2,2)\n",
    "plt.plot(pars_hat['R'])\n",
    "try:\n",
    "    plt.plot(pars_true['R'])\n",
    "except:\n",
    "    pass\n",
    "    \n",
    "plt.legend(['true', 'est'])\n",
    "plt.title('R')\n",
    "plt.subplot(2,2,3)\n",
    "plt.plot(np.sort(np.linalg.eig(pars_hat['A'])[0]))\n",
    "try:\n",
    "    plt.plot(np.sort(np.linalg.eig(pars_true['A'])[0]))\n",
    "except:\n",
    "    pass\n",
    "plt.legend(['true', 'est'])\n",
    "plt.title('eig(A)')\n",
    "plt.title('eigenvalues of A')\n",
    "plt.show()\n",
    "\n",
    "\"\"\" second batch of figures\"\"\"\n",
    "\n",
    "covy_h= np.dot( np.dot(pars_hat['C'], Pi),pars_hat['C'].transpose()) + pars_hat['R']\n",
    "\n",
    "try: \n",
    "    covy_t= np.dot(np.dot(pars_true['C'], Pi_true),pars_true['C'].transpose()) + np.diag(pars_true['R'])\n",
    "    covy_tl_t=(np.dot(np.dot(pars_true['C'],np.dot(pars_true['A'], Pi_true)),pars_true['C'].transpose()))\n",
    "    plot_truth = True\n",
    "except:\n",
    "    plot_truth = False\n",
    "    \n",
    "y_tl = np.zeros([2*p,T-1])\n",
    "y_tl[range(p),:] = data[range(0,T-1),:].T\n",
    "y_tl[range(p,2*p),:] = data[range(1,T),:].T\n",
    "covy = np.cov(y_tl)\n",
    "\n",
    "covy_e=    covy[np.ix_(range(p),range(p))]\n",
    "covy_tl_e= covy[np.ix_(range(p,2*p),range(0,p))]\n",
    "\n",
    "\n",
    "sub_pops = loadfile['sub_pops']\n",
    "covy_tl_h= np.dot(np.dot(pars_hat['C'], np.dot(pars_hat['A'],Pi)), pars_hat['C'].transpose())\n",
    "idx_stitched = np.ones([p,p],dtype = bool)\n",
    "for i in range(len(sub_pops)):\n",
    "    if len(sub_pops[i])>0:\n",
    "        idx_stitched[np.ix_(sub_pops[i],sub_pops[i])] = False\n",
    "plt.imshow(idx_stitched,interpolation='none')\n",
    "\n",
    "plt.figure(3, figsize=(20,10))\n",
    "plt.subplot(1,3,1)\n",
    "if plot_truth:\n",
    "    plt.plot(covy_e[np.invert(idx_stitched)], covy_t[np.invert(idx_stitched)], '.')\n",
    "    plt.title('obs. emp vs. obs. true')\n",
    "plt.ylabel('instantaneous')\n",
    "plt.subplot(1,3,2)\n",
    "plt.plot(covy_e[np.invert(idx_stitched)], covy_h[np.invert(idx_stitched)], '.')\n",
    "plt.title('obs. emp vs. obs. stitched')\n",
    "plt.subplot(1,3,3)\n",
    "if plot_truth:\n",
    "    plt.plot(covy_t[np.invert(idx_stitched)], covy_h[np.invert(idx_stitched)], '.')\n",
    "    plt.title('obs. true vs. obs. stitched')\n",
    "\n",
    "plt.figure(4, figsize=(20,10))\n",
    "plt.subplot(1,3,1)\n",
    "if plot_truth:\n",
    "    plt.plot(covy_tl_e[np.invert(idx_stitched)], covy_tl_t[np.invert(idx_stitched)], '.')\n",
    "plt.ylabel('time-lagged')\n",
    "plt.title('obs. emp vs. obs. true')\n",
    "plt.subplot(1,3,2)\n",
    "plt.plot(covy_tl_e[np.invert(idx_stitched)], covy_tl_h[np.invert(idx_stitched)], '.')\n",
    "plt.title('obs. emp vs. obs. stitched')\n",
    "plt.subplot(1,3,3)\n",
    "if plot_truth:\n",
    "    plt.plot(covy_tl_t[np.invert(idx_stitched)], covy_tl_h[np.invert(idx_stitched)], '.')\n",
    "    plt.title('obs. non-observed true vs. obs. stitched')\n",
    "\n",
    "plt.figure(5, figsize=(20,10))\n",
    "plt.subplot(1,3,1)\n",
    "if plot_truth:\n",
    "    plt.plot(covy_e[idx_stitched], covy_t[idx_stitched], '.')\n",
    "    plt.title('non-obs. emp vs. non-obs. true')\n",
    "plt.subplot(1,3,2)\n",
    "plt.plot(covy_e[idx_stitched], covy_h[idx_stitched], '.')\n",
    "plt.title('non-obs. emp vs. non-obs. stitched')\n",
    "plt.subplot(1,3,3)\n",
    "if plot_truth:\n",
    "    plt.plot(covy_t[idx_stitched], covy_h[idx_stitched], '.')\n",
    "    plt.title('non-obs. true vs. non-obs. titched')\n",
    "\n",
    "plt.figure(6, figsize=(20,10))\n",
    "plt.subplot(1,3,1)\n",
    "if plot_truth:\n",
    "    plt.plot(covy_tl_e[idx_stitched], covy_tl_t[idx_stitched], '.')\n",
    "    plt.title('non-obs. emp vs. non-obs. true')\n",
    "plt.subplot(1,3,2)\n",
    "plt.plot(covy_tl_e[idx_stitched], covy_tl_h[idx_stitched], '.')\n",
    "plt.title('non-obs. emp vs. non-obs. stitched')\n",
    "plt.subplot(1,3,3)\n",
    "if plot_truth:\n",
    "    plt.plot(covy_tl_t[idx_stitched], covy_tl_h[idx_stitched], '.')\n",
    "    plt.title('non-obs. true vs. non-obs. stitched')\n",
    "    \n",
    "    \n",
    "print('corr(y_t,y_t) stitchted: ', np.corrcoef(covy_e[idx_stitched], covy_h[idx_stitched]))\n",
    "print('corr(y_t,y_t) observed: ', np.corrcoef(covy_e[np.invert(idx_stitched)], covy_h[np.invert(idx_stitched)]))\n",
    "\n",
    "print('corr(y_t,y_t-1) stitchted: ', np.corrcoef(covy_tl_e[idx_stitched], covy_tl_h[idx_stitched]))\n",
    "print('corr(y_t,y_t-1) observed: ', np.corrcoef(covy_tl_e[np.invert(idx_stitched)], covy_tl_h[np.invert(idx_stitched)]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize goodnes of naive SSID initialisation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "spikes = loadmat('/home/marcel/Desktop/Projects/Stitching/results/cosyne_poster/gb_net/spikes_20trials_10msBins')\n",
    "spikes= spikes['spikes_out']\n",
    "loadfile = np.load('/home/marcel/Desktop/Projects/Stitching/results/cosyne_poster/experiment_1/init/init_experiment.npz')\n",
    "\n",
    "p, T = spikes[0][0].shape\n",
    "idx_n = np.sort(np.random.choice(1000, size=p, replace=False))\n",
    "data = np.vstack([spikes[i][0].T[:,idx_n] for i in range(spikes.size)]).astype(np.float)\n",
    "T *= spikes.size\n",
    "\n",
    "n = 10\n",
    "\n",
    "neuron_shuffle = loadfile['neuron_shuffle']\n",
    "\n",
    "data = data[:,neuron_shuffle]\n",
    "\n",
    "initkey =  'params_naive'\n",
    "\n",
    "pars_init = loadfile[initkey].reshape(1,)[0]\n",
    "tmp = {}\n",
    "for j in range(len(pars_init.keys())):\n",
    "    tmp[str(pars_init.keys()[j])] =  pars_init.values()[j]\n",
    "pars_init = tmp    \n",
    "\n",
    "pars_init['R'] = np.diag(pars_init['R'])\n",
    "pars_init['V0'] = pars_init['Q']\n",
    "\n",
    "pars_hat = pars_init.copy()\n",
    "pars_hat['R'] = np.diag(pars_hat['R'])\n",
    "\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Pi = sp.linalg.solve_discrete_lyapunov(pars_hat['A'], pars_hat['Q'])\n",
    "Pi = pars_hat['Pi']\n",
    "plt.figure(1,figsize=(15,22))\n",
    "try:\n",
    "    Pi_true = sp.linalg.solve_discrete_lyapunov(pars_true['A'], pars_true['Q'])\n",
    "    tmp1 = pars_true['C'].dot(Pi_true.dot(pars_true['C'].transpose())) + np.diag(pars_true['R'])\n",
    "except:\n",
    "    cov_all = np.cov(np.hstack([data[1:], data[:-1]]).T)\n",
    "    tmp1 = cov_all[np.ix_(np.arange(p), np.arange(p))]\n",
    "tmp2 = pars_hat['C'].dot(Pi.dot(pars_hat['C'].transpose())) + pars_hat['R']    \n",
    "m = np.min((tmp1-np.diag(np.diag(tmp1))).min(),(tmp2-np.diag(np.diag(tmp2))).min())\n",
    "M = np.max((tmp1-np.diag(np.diag(tmp1))).max(),(tmp2-np.diag(np.diag(tmp2))).max())\n",
    "\n",
    "plt.subplot(2,3,1)\n",
    "plt.imshow(tmp1-np.diag(np.diag(tmp1)),interpolation='none')\n",
    "plt.clim(m,M)\n",
    "plt.colorbar()\n",
    "plt.title('true instantaneous covs')\n",
    "plt.subplot(2,3,2)\n",
    "plt.imshow(tmp2-np.diag(np.diag(tmp2)), interpolation='none')\n",
    "plt.clim(m,M)\n",
    "plt.colorbar()\n",
    "plt.title('estimated instantaneous covs')\n",
    "plt.subplot(2,3,3)\n",
    "plt.plot(tmp1[:], tmp2[:], '.')\n",
    "plt.xlabel('true')\n",
    "plt.ylabel('est')\n",
    "\n",
    "try:\n",
    "    tmp1 = pars_true['C'].dot(pars_true['A']).dot(Pi_true.dot(pars_true['C'].transpose()))\n",
    "except:\n",
    "    tmp1 = cov_all[np.ix_(np.arange(0, p), np.arange(p+1 , 2*p))]\n",
    "tmp2 = pars_hat['C'].dot(pars_hat['A']).dot(Pi.dot(pars_hat['C'].transpose()))     \n",
    "m = np.min(tmp1.min(),tmp2.min())\n",
    "M = np.max(tmp1.max(),tmp2.max())\n",
    "\n",
    "plt.subplot(2,3,4)\n",
    "plt.imshow(tmp1,interpolation='none')\n",
    "plt.clim(m,M)\n",
    "plt.colorbar()\n",
    "plt.title('true time_lagged covs')\n",
    "plt.subplot(2,3,5)\n",
    "plt.imshow(tmp2, interpolation='none')\n",
    "plt.clim(m,M)\n",
    "plt.colorbar()\n",
    "plt.title('estimated time-lagged covs')\n",
    "plt.subplot(2,3,6)\n",
    "plt.plot(tmp1[:], tmp2[:], '.')\n",
    "plt.xlabel('true')\n",
    "plt.ylabel('est')\n",
    "\n",
    "\n",
    "plt.figure(2,figsize=(15,15))\n",
    "plt.subplot(2,2,1)\n",
    "plt.plot(pars_hat['d'])\n",
    "try:\n",
    "    plt.plot(pars_true['d'])\n",
    "except:\n",
    "    pass\n",
    "plt.legend(['true', 'est'])\n",
    "plt.title('d')\n",
    "plt.subplot(2,2,2)\n",
    "plt.plot(pars_hat['R'])\n",
    "try:\n",
    "    plt.plot(pars_true['R'])\n",
    "except:\n",
    "    pass\n",
    "    \n",
    "plt.legend(['true', 'est'])\n",
    "plt.title('R')\n",
    "plt.subplot(2,2,3)\n",
    "plt.plot(np.sort(np.linalg.eig(pars_hat['A'])[0]))\n",
    "try:\n",
    "    plt.plot(np.sort(np.linalg.eig(pars_true['A'])[0]))\n",
    "except:\n",
    "    pass\n",
    "plt.legend(['true', 'est'])\n",
    "plt.title('eig(A)')\n",
    "plt.title('eigenvalues of A')\n",
    "plt.show()\n",
    "\n",
    "\"\"\" second batch of figures\"\"\"\n",
    "\n",
    "covy_h= np.dot( np.dot(pars_hat['C'], Pi),pars_hat['C'].transpose()) + pars_hat['R']\n",
    "\n",
    "try: \n",
    "    covy_t= np.dot(np.dot(pars_true['C'], Pi_true),pars_true['C'].transpose()) + np.diag(pars_true['R'])\n",
    "    covy_tl_t=(np.dot(np.dot(pars_true['C'],np.dot(pars_true['A'], Pi_true)),pars_true['C'].transpose()))\n",
    "    plot_truth = True\n",
    "except:\n",
    "    plot_truth = False\n",
    "    \n",
    "y_tl = np.zeros([2*p,T-1])\n",
    "y_tl[range(p),:] = data[range(0,T-1),:].T\n",
    "y_tl[range(p,2*p),:] = data[range(1,T),:].T\n",
    "covy = np.cov(y_tl)\n",
    "\n",
    "covy_e=    covy[np.ix_(range(p),range(p))]\n",
    "covy_tl_e= covy[np.ix_(range(p,2*p),range(0,p))]\n",
    "\n",
    "covy_tl_h= np.dot(np.dot(pars_hat['C'], np.dot(pars_hat['A'],Pi)), pars_hat['C'].transpose())\n",
    "idx_stitched = np.ones([p,p],dtype = bool)\n",
    "for i in range(len(obs_scheme.sub_pops)):\n",
    "    if len(obs_scheme.sub_pops[i])>0:\n",
    "        idx_stitched[np.ix_(obs_scheme.sub_pops[i],obs_scheme.sub_pops[i])] = False\n",
    "plt.imshow(idx_stitched,interpolation='none')\n",
    "\n",
    "plt.figure(3, figsize=(20,10))\n",
    "plt.subplot(1,3,1)\n",
    "if plot_truth:\n",
    "    plt.plot(covy_e[np.invert(idx_stitched)], covy_t[np.invert(idx_stitched)], '.')\n",
    "    plt.title('obs. emp vs. obs. true')\n",
    "plt.ylabel('instantaneous')\n",
    "plt.subplot(1,3,2)\n",
    "plt.plot(covy_e[np.invert(idx_stitched)], covy_h[np.invert(idx_stitched)], '.')\n",
    "plt.title('obs. emp vs. obs. stitched')\n",
    "plt.subplot(1,3,3)\n",
    "if plot_truth:\n",
    "    plt.plot(covy_t[np.invert(idx_stitched)], covy_h[np.invert(idx_stitched)], '.')\n",
    "    plt.title('obs. true vs. obs. stitched')\n",
    "\n",
    "plt.figure(4, figsize=(20,10))\n",
    "plt.subplot(1,3,1)\n",
    "if plot_truth:\n",
    "    plt.plot(covy_tl_e[np.invert(idx_stitched)], covy_tl_t[np.invert(idx_stitched)], '.')\n",
    "plt.ylabel('time-lagged')\n",
    "plt.title('obs. emp vs. obs. true')\n",
    "plt.subplot(1,3,2)\n",
    "plt.plot(covy_tl_e[np.invert(idx_stitched)], covy_tl_h[np.invert(idx_stitched)], '.')\n",
    "plt.title('obs. emp vs. obs. stitched')\n",
    "plt.subplot(1,3,3)\n",
    "if plot_truth:\n",
    "    plt.plot(covy_tl_t[np.invert(idx_stitched)], covy_tl_h[np.invert(idx_stitched)], '.')\n",
    "    plt.title('obs. non-observed true vs. obs. stitched')\n",
    "\n",
    "plt.figure(5, figsize=(20,10))\n",
    "plt.subplot(1,3,1)\n",
    "if plot_truth:\n",
    "    plt.plot(covy_e[idx_stitched], covy_t[idx_stitched], '.')\n",
    "    plt.title('non-obs. emp vs. non-obs. true')\n",
    "plt.subplot(1,3,2)\n",
    "plt.plot(covy_e[idx_stitched], covy_h[idx_stitched], '.')\n",
    "plt.title('non-obs. emp vs. non-obs. stitched')\n",
    "plt.subplot(1,3,3)\n",
    "if plot_truth:\n",
    "    plt.plot(covy_t[idx_stitched], covy_h[idx_stitched], '.')\n",
    "    plt.title('non-obs. true vs. non-obs. titched')\n",
    "\n",
    "plt.figure(6, figsize=(20,10))\n",
    "plt.subplot(1,3,1)\n",
    "if plot_truth:\n",
    "    plt.plot(covy_tl_e[idx_stitched], covy_tl_t[idx_stitched], '.')\n",
    "    plt.title('non-obs. emp vs. non-obs. true')\n",
    "plt.subplot(1,3,2)\n",
    "plt.plot(covy_tl_e[idx_stitched], covy_tl_h[idx_stitched], '.')\n",
    "plt.title('non-obs. emp vs. non-obs. stitched')\n",
    "plt.subplot(1,3,3)\n",
    "if plot_truth:\n",
    "    plt.plot(covy_tl_t[idx_stitched], covy_tl_h[idx_stitched], '.')\n",
    "    plt.title('non-obs. true vs. non-obs. stitched')\n",
    "    \n",
    "    \n",
    "print('corr(y_t,y_t) stitchted: ', np.corrcoef(covy_e[idx_stitched], covy_h[idx_stitched]))\n",
    "print('corr(y_t,y_t) observed: ', np.corrcoef(covy_e[np.invert(idx_stitched)], covy_h[np.invert(idx_stitched)]))\n",
    "\n",
    "print('corr(y_t,y_t-1) stitchted: ', np.corrcoef(covy_tl_e[idx_stitched], covy_tl_h[idx_stitched]))\n",
    "print('corr(y_t,y_t-1) observed: ', np.corrcoef(covy_tl_e[np.invert(idx_stitched)], covy_tl_h[np.invert(idx_stitched)]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continue big sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "               \n",
    "\n",
    "print('loading data')\n",
    "spikes = loadmat('/home/marcel/Desktop/Projects/Stitching/results/cosyne_poster/gb_net/spikes_20trials_10msBins')\n",
    "spikes= spikes['spikes_out']\n",
    "\n",
    "\n",
    "\n",
    "print('concatenating data')\n",
    "p, T = 1000, 6000\n",
    "#data = spikes[0][0].T\n",
    "idx_n = np.sort(np.random.choice(1000, size=p, replace=False))\n",
    "data = np.vstack([spikes[i][0].T[:,idx_n] for i in range(spikes.size)]).astype(np.float)\n",
    "T *= spikes.size\n",
    "\n",
    "loadfile = np.load('/home/marcel/Desktop/Projects/Stitching/results/cosyne_poster/experiment_1/init/init_experiment.npz')\n",
    "neuron_shuffle = loadfile['neuron_shuffle']\n",
    "data = data[:,neuron_shuffle]\n",
    "\n",
    "n = 10\n",
    "\n",
    "print(data.shape)\n",
    "\n",
    "###################\n",
    "#    EM cycles    #\n",
    "###################\n",
    "\n",
    "print('loading parameters')\n",
    "loadfile = np.load('/home/marcel/Desktop/Projects/Stitching/results/cosyne_poster/experiment_1/fits/params_naive_p1000_iter300.npz')\n",
    "pars_init = loadfile['estPars'].reshape(1,)[0]\n",
    "pars_init['R'] = np.diag(pars_init['R'])\n",
    "\n",
    "sub_pops = tuple(loadfile['sub_pops'].tolist())\n",
    "obs_pops =tuple(loadfile['obs_pops'].tolist())\n",
    "obs_time = tuple(loadfile['obs_time'].tolist())\n",
    "obs_scheme = ObservationScheme(p, T, sub_pops, obs_pops, obs_time)\n",
    "\n",
    "\n",
    "model = init_LDS_model(pars_init, data, obs_scheme) # set to initialisation\n",
    "\n",
    "print('(p,T,n)', (p,T,n))\n",
    "print('len sub_pops', [len(item) for item in obs_scheme.sub_pops])\n",
    "\n",
    "#stats_init,_ = collect_LDS_stats(model)\n",
    "\n",
    "print('fitting')\n",
    "likes = [update(model) for _ in progprint_xrange(100)]\n",
    "stats_hat,pars_hat = collect_LDS_stats(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(likes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.io import savemat\n",
    "broken = False\n",
    "save_file = '/home/marcel/Desktop/Projects/Stitching/results/cosyne_poster/experiment_1/fits/params_naive_p1000_iter400'\n",
    "\n",
    "eps = - np.inf\n",
    "save_file_m = {'ifBroken':broken,\n",
    "               'll' : likes, \n",
    "               'T' : model.states_list[0].T, \n",
    "               'Trial': len(model.states_list), \n",
    "               'epsilon':eps,\n",
    "               'initPars':pars_init,\n",
    "               'estPars': pars_hat,\n",
    "               'stats_h': stats_hat,\n",
    "               'sub_pops' : obs_scheme.sub_pops,\n",
    "               'obs_pops' : obs_scheme.obs_pops,\n",
    "               'obs_time' : obs_scheme.obs_time}\n",
    "\n",
    "savemat(save_file,save_file_m) # does the actual saving\n",
    "\n",
    "np.savez(save_file, \n",
    "        broken=broken,\n",
    "        ll=likes,\n",
    "        T=model.states_list[0].T, \n",
    "        Trial=len(model.states_list), \n",
    "        epsilon=eps,\n",
    "        initPars=pars_init,\n",
    "        estPars =pars_hat,\n",
    "        stats_h = stats_hat,\n",
    "        sub_pops=obs_scheme.sub_pops,            \n",
    "        obs_time=obs_scheme.obs_time,            \n",
    "        obs_pops=obs_scheme.obs_pops)     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
